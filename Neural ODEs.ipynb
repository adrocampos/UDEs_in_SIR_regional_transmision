{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21990add",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a912d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c4f91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Flux.frequencies in module DataDrivenDiffEq conflicts with an existing identifier.\n",
      "┌ Info: DataDrivenDiffEq : OccamNet is available.\n",
      "└ @ DataDrivenDiffEq /Users/adrocampos/.julia/packages/DataDrivenDiffEq/fivVr/src/DataDrivenDiffEq.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/covid19/discovering_missing_terms/Project.toml`\n",
      " \u001b[90m [336ed68f] \u001b[39mCSV v0.10.7\n",
      "\u001b[32m⌃\u001b[39m\u001b[90m [2445eb08] \u001b[39mDataDrivenDiffEq v0.8.6\n",
      " \u001b[90m [a93c6f00] \u001b[39mDataFrames v1.4.3\n",
      " \u001b[90m [aae7a2af] \u001b[39mDiffEqFlux v1.52.0\n",
      " \u001b[90m [41bf760c] \u001b[39mDiffEqSensitivity v6.79.0\n",
      " \u001b[90m [0c46a032] \u001b[39mDifferentialEquations v7.6.0\n",
      " \u001b[90m [5789e2e9] \u001b[39mFileIO v1.16.0\n",
      "\u001b[32m⌃\u001b[39m\u001b[90m [587475ba] \u001b[39mFlux v0.13.7\n",
      " \u001b[90m [7073ff75] \u001b[39mIJulia v1.23.3\n",
      " \u001b[90m [033835bb] \u001b[39mJLD2 v0.4.28\n",
      "\u001b[32m⌃\u001b[39m\u001b[90m [b2108857] \u001b[39mLux v0.4.34\n",
      "\u001b[32m⌃\u001b[39m\u001b[90m [961ee093] \u001b[39mModelingToolkit v8.33.0\n",
      "\u001b[32m⌃\u001b[39m\u001b[90m [429524aa] \u001b[39mOptim v1.7.3\n",
      " \u001b[90m [7f7a1694] \u001b[39mOptimization v3.9.2\n",
      " \u001b[90m [36348300] \u001b[39mOptimizationOptimJL v0.1.4\n",
      " \u001b[90m [1dea7af3] \u001b[39mOrdinaryDiffEq v6.31.2\n",
      "\u001b[32m⌃\u001b[39m\u001b[90m [91a5bcdd] \u001b[39mPlots v1.36.1\n",
      " \u001b[90m [e88e6eb3] \u001b[39mZygote v0.6.49\n",
      " \u001b[90m [8bb1440f] \u001b[39mDelimitedFiles\n",
      " \u001b[90m [37e2e46d] \u001b[39mLinearAlgebra\n",
      " \u001b[90m [9a3f8284] \u001b[39mRandom\n",
      "\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m have new versions available and may be upgradable.\n"
     ]
    }
   ],
   "source": [
    "using OrdinaryDiffEq\n",
    "using ModelingToolkit\n",
    "using DataDrivenDiffEq\n",
    "using LinearAlgebra, Optim\n",
    "using DiffEqFlux, Flux\n",
    "using DataFrames\n",
    "\n",
    "\n",
    "using Random\n",
    "using Plots\n",
    "gr()\n",
    "using CSV\n",
    "\n",
    "\n",
    "using Pkg\n",
    "\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7ee6e",
   "metadata": {},
   "source": [
    "### ODE data for simmulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = Random.default_rng()\n",
    "u0 = Float32[2.0; 0.0]\n",
    "datasize = 30\n",
    "tspan = (0.0f0, 1.5f0)\n",
    "tsteps = range(tspan[1], tspan[2], length = datasize)\n",
    "\n",
    "function trueODEfunc(du, u, p, t)\n",
    "    true_A = [-0.1 2.0; -2.0 -0.1]\n",
    "    du .= ((u.^3)'true_A)'\n",
    "end\n",
    "\n",
    "prob_trueode = ODEProblem(trueODEfunc, u0, tspan)\n",
    "ode_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76729ed2",
   "metadata": {},
   "source": [
    "### This is an Neural ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "dudt2 = Lux.Chain(x -> x.^3,\n",
    "                  Lux.Dense(2, 50, tanh),\n",
    "                  Lux.Dense(50, 2))\n",
    "p, st = Lux.setup(rng, dudt2)\n",
    "prob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_neuralode(p)\n",
    "  Array(prob_neuralode(u0, p, st)[1])\n",
    "end\n",
    "\n",
    "function loss_neuralode(p)\n",
    "    pred = predict_neuralode(p)\n",
    "    loss = sum(abs2, ode_data .- pred)\n",
    "    return loss, pred\n",
    "end\n",
    "\n",
    "# Do not plot by default for the documentation\n",
    "# Users should change doplot=true to see the plots callbacks\n",
    "callback = function (p, l, pred; doplot = true)\n",
    "  println(l)\n",
    "  # plot current prediction against data\n",
    "  if doplot\n",
    "    plt = scatter(tsteps, ode_data[1,:], label = \"data\")\n",
    "    scatter!(plt, tsteps, pred[1,:], label = \"prediction\")\n",
    "    display(plot(plt))\n",
    "  end\n",
    "  return false\n",
    "end\n",
    "\n",
    "pinit = Lux.ComponentArray(p)\n",
    "callback(pinit, loss_neuralode(pinit)...; doplot=true)\n",
    "\n",
    "# use Optimization.jl to solve the problem\n",
    "adtype = Optimization.AutoZygote()\n",
    "\n",
    "optf = Optimization.OptimizationFunction((x, p) -> loss_neuralode(x), adtype)\n",
    "optprob = Optimization.OptimizationProblem(optf, pinit)\n",
    "\n",
    "result_neuralode = Optimization.solve(optprob,\n",
    "                                       ADAM(0.05),\n",
    "                                       callback = callback,\n",
    "                                       maxiters = 300)\n",
    "\n",
    "optprob2 = remake(optprob,u0 = result_neuralode.u)\n",
    "\n",
    "result_neuralode2 = Optimization.solve(optprob2,\n",
    "                                        Optim.BFGS(initial_stepnorm=0.01),\n",
    "                                        callback=callback,\n",
    "                                        allow_f_increases = false)\n",
    "\n",
    "callback(result_neuralode2.u, loss_neuralode(result_neuralode2.u)...; doplot=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9094a1da",
   "metadata": {},
   "source": [
    "# Our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0475ceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/Users/adrocampos/covid19/synth_data/\"\n",
    "regions = [\"2\", \"3\", \"5\", \"10\", \"15\", \"20\", \"30\"][1]\n",
    "mobility_type = [\"inv_dist\", \"border\", \"neighbor\"][2]\n",
    "initially_recovered = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f71786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>2×5 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">id</th><th style = \"text-align: left;\">N</th><th style = \"text-align: left;\">density</th><th style = \"text-align: left;\">x</th><th style = \"text-align: left;\">y</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2780</td><td style = \"text-align: right;\">308.973</td><td style = \"text-align: right;\">0.246368</td><td style = \"text-align: right;\">0.714476</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1081</td><td style = \"text-align: right;\">154.375</td><td style = \"text-align: right;\">0.315868</td><td style = \"text-align: right;\">3.86025</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& id & N & density & x & y\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 2780 & 308.973 & 0.246368 & 0.714476 \\\\\n",
       "\t2 & 2 & 1081 & 154.375 & 0.315868 & 3.86025 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m2×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m id    \u001b[0m\u001b[1m N     \u001b[0m\u001b[1m density \u001b[0m\u001b[1m x        \u001b[0m\u001b[1m y        \u001b[0m\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "─────┼───────────────────────────────────────────\n",
       "   1 │     1   2780  308.973  0.246368  0.714476\n",
       "   2 │     2   1081  154.375  0.315868  3.86025"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = CSV.File(data_dir * \"positions_\" * regions * \"_regions.csv\")\n",
    "positions = DataFrame(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b0c73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd0a59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5001×7 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">4976 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">t</th><th style = \"text-align: left;\">S1</th><th style = \"text-align: left;\">I1</th><th style = \"text-align: left;\">R1</th><th style = \"text-align: left;\">S2</th><th style = \"text-align: left;\">I2</th><th style = \"text-align: left;\">R2</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">2773.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1078.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">2772.93</td><td style = \"text-align: right;\">6.99984</td><td style = \"text-align: right;\">0.0699992</td><td style = \"text-align: right;\">1077.97</td><td style = \"text-align: right;\">2.99992</td><td style = \"text-align: right;\">0.0299996</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">2772.86</td><td style = \"text-align: right;\">6.9997</td><td style = \"text-align: right;\">0.139997</td><td style = \"text-align: right;\">1077.94</td><td style = \"text-align: right;\">2.99985</td><td style = \"text-align: right;\">0.0599985</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">0.3</td><td style = \"text-align: right;\">2772.79</td><td style = \"text-align: right;\">6.99959</td><td style = \"text-align: right;\">0.209993</td><td style = \"text-align: right;\">1077.91</td><td style = \"text-align: right;\">2.99979</td><td style = \"text-align: right;\">0.0899967</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">0.4</td><td style = \"text-align: right;\">2772.72</td><td style = \"text-align: right;\">6.99951</td><td style = \"text-align: right;\">0.279989</td><td style = \"text-align: right;\">1077.88</td><td style = \"text-align: right;\">2.99974</td><td style = \"text-align: right;\">0.119994</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">0.5</td><td style = \"text-align: right;\">2772.65</td><td style = \"text-align: right;\">6.99945</td><td style = \"text-align: right;\">0.349984</td><td style = \"text-align: right;\">1077.85</td><td style = \"text-align: right;\">2.9997</td><td style = \"text-align: right;\">0.149992</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">0.6</td><td style = \"text-align: right;\">2772.58</td><td style = \"text-align: right;\">6.99942</td><td style = \"text-align: right;\">0.419978</td><td style = \"text-align: right;\">1077.82</td><td style = \"text-align: right;\">2.99967</td><td style = \"text-align: right;\">0.179988</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">0.7</td><td style = \"text-align: right;\">2772.51</td><td style = \"text-align: right;\">6.99942</td><td style = \"text-align: right;\">0.489972</td><td style = \"text-align: right;\">1077.79</td><td style = \"text-align: right;\">2.99964</td><td style = \"text-align: right;\">0.209985</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">0.8</td><td style = \"text-align: right;\">2772.44</td><td style = \"text-align: right;\">6.99945</td><td style = \"text-align: right;\">0.559966</td><td style = \"text-align: right;\">1077.76</td><td style = \"text-align: right;\">2.99963</td><td style = \"text-align: right;\">0.239981</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">0.9</td><td style = \"text-align: right;\">2772.37</td><td style = \"text-align: right;\">6.9995</td><td style = \"text-align: right;\">0.629961</td><td style = \"text-align: right;\">1077.73</td><td style = \"text-align: right;\">2.99962</td><td style = \"text-align: right;\">0.269978</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2772.3</td><td style = \"text-align: right;\">6.99958</td><td style = \"text-align: right;\">0.699956</td><td style = \"text-align: right;\">1077.7</td><td style = \"text-align: right;\">2.99963</td><td style = \"text-align: right;\">0.299974</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">1.1</td><td style = \"text-align: right;\">2772.23</td><td style = \"text-align: right;\">6.99968</td><td style = \"text-align: right;\">0.769953</td><td style = \"text-align: right;\">1077.67</td><td style = \"text-align: right;\">2.99964</td><td style = \"text-align: right;\">0.32997</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">1.2</td><td style = \"text-align: right;\">2772.16</td><td style = \"text-align: right;\">6.99981</td><td style = \"text-align: right;\">0.83995</td><td style = \"text-align: right;\">1077.64</td><td style = \"text-align: right;\">2.99967</td><td style = \"text-align: right;\">0.359967</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4990</td><td style = \"text-align: right;\">498.9</td><td style = \"text-align: right;\">747.171</td><td style = \"text-align: right;\">28.7668</td><td style = \"text-align: right;\">2004.06</td><td style = \"text-align: right;\">290.545</td><td style = \"text-align: right;\">11.1866</td><td style = \"text-align: right;\">779.268</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4991</td><td style = \"text-align: right;\">499.0</td><td style = \"text-align: right;\">746.894</td><td style = \"text-align: right;\">28.7561</td><td style = \"text-align: right;\">2004.35</td><td style = \"text-align: right;\">290.437</td><td style = \"text-align: right;\">11.1825</td><td style = \"text-align: right;\">779.38</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4992</td><td style = \"text-align: right;\">499.1</td><td style = \"text-align: right;\">746.617</td><td style = \"text-align: right;\">28.7455</td><td style = \"text-align: right;\">2004.64</td><td style = \"text-align: right;\">290.33</td><td style = \"text-align: right;\">11.1783</td><td style = \"text-align: right;\">779.492</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4993</td><td style = \"text-align: right;\">499.2</td><td style = \"text-align: right;\">746.34</td><td style = \"text-align: right;\">28.7348</td><td style = \"text-align: right;\">2004.93</td><td style = \"text-align: right;\">290.222</td><td style = \"text-align: right;\">11.1742</td><td style = \"text-align: right;\">779.604</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4994</td><td style = \"text-align: right;\">499.3</td><td style = \"text-align: right;\">746.063</td><td style = \"text-align: right;\">28.7242</td><td style = \"text-align: right;\">2005.21</td><td style = \"text-align: right;\">290.115</td><td style = \"text-align: right;\">11.17</td><td style = \"text-align: right;\">779.715</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4995</td><td style = \"text-align: right;\">499.4</td><td style = \"text-align: right;\">745.787</td><td style = \"text-align: right;\">28.7135</td><td style = \"text-align: right;\">2005.5</td><td style = \"text-align: right;\">290.007</td><td style = \"text-align: right;\">11.1659</td><td style = \"text-align: right;\">779.827</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4996</td><td style = \"text-align: right;\">499.5</td><td style = \"text-align: right;\">745.51</td><td style = \"text-align: right;\">28.7029</td><td style = \"text-align: right;\">2005.79</td><td style = \"text-align: right;\">289.899</td><td style = \"text-align: right;\">11.1618</td><td style = \"text-align: right;\">779.939</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4997</td><td style = \"text-align: right;\">499.6</td><td style = \"text-align: right;\">745.234</td><td style = \"text-align: right;\">28.6923</td><td style = \"text-align: right;\">2006.07</td><td style = \"text-align: right;\">289.792</td><td style = \"text-align: right;\">11.1576</td><td style = \"text-align: right;\">780.05</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4998</td><td style = \"text-align: right;\">499.7</td><td style = \"text-align: right;\">744.958</td><td style = \"text-align: right;\">28.6816</td><td style = \"text-align: right;\">2006.36</td><td style = \"text-align: right;\">289.685</td><td style = \"text-align: right;\">11.1535</td><td style = \"text-align: right;\">780.162</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4999</td><td style = \"text-align: right;\">499.8</td><td style = \"text-align: right;\">744.682</td><td style = \"text-align: right;\">28.671</td><td style = \"text-align: right;\">2006.65</td><td style = \"text-align: right;\">289.577</td><td style = \"text-align: right;\">11.1494</td><td style = \"text-align: right;\">780.273</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5000</td><td style = \"text-align: right;\">499.9</td><td style = \"text-align: right;\">744.406</td><td style = \"text-align: right;\">28.6604</td><td style = \"text-align: right;\">2006.93</td><td style = \"text-align: right;\">289.47</td><td style = \"text-align: right;\">11.1453</td><td style = \"text-align: right;\">780.385</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5001</td><td style = \"text-align: right;\">500.0</td><td style = \"text-align: right;\">744.13</td><td style = \"text-align: right;\">28.6498</td><td style = \"text-align: right;\">2007.22</td><td style = \"text-align: right;\">289.363</td><td style = \"text-align: right;\">11.1411</td><td style = \"text-align: right;\">780.496</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& t & S1 & I1 & R1 & S2 & I2 & R2\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0 & 2773.0 & 7.0 & 0.0 & 1078.0 & 3.0 & 0.0 \\\\\n",
       "\t2 & 0.1 & 2772.93 & 6.99984 & 0.0699992 & 1077.97 & 2.99992 & 0.0299996 \\\\\n",
       "\t3 & 0.2 & 2772.86 & 6.9997 & 0.139997 & 1077.94 & 2.99985 & 0.0599985 \\\\\n",
       "\t4 & 0.3 & 2772.79 & 6.99959 & 0.209993 & 1077.91 & 2.99979 & 0.0899967 \\\\\n",
       "\t5 & 0.4 & 2772.72 & 6.99951 & 0.279989 & 1077.88 & 2.99974 & 0.119994 \\\\\n",
       "\t6 & 0.5 & 2772.65 & 6.99945 & 0.349984 & 1077.85 & 2.9997 & 0.149992 \\\\\n",
       "\t7 & 0.6 & 2772.58 & 6.99942 & 0.419978 & 1077.82 & 2.99967 & 0.179988 \\\\\n",
       "\t8 & 0.7 & 2772.51 & 6.99942 & 0.489972 & 1077.79 & 2.99964 & 0.209985 \\\\\n",
       "\t9 & 0.8 & 2772.44 & 6.99945 & 0.559966 & 1077.76 & 2.99963 & 0.239981 \\\\\n",
       "\t10 & 0.9 & 2772.37 & 6.9995 & 0.629961 & 1077.73 & 2.99962 & 0.269978 \\\\\n",
       "\t11 & 1.0 & 2772.3 & 6.99958 & 0.699956 & 1077.7 & 2.99963 & 0.299974 \\\\\n",
       "\t12 & 1.1 & 2772.23 & 6.99968 & 0.769953 & 1077.67 & 2.99964 & 0.32997 \\\\\n",
       "\t13 & 1.2 & 2772.16 & 6.99981 & 0.83995 & 1077.64 & 2.99967 & 0.359967 \\\\\n",
       "\t14 & 1.3 & 2772.09 & 6.99997 & 0.909949 & 1077.61 & 2.9997 & 0.389963 \\\\\n",
       "\t15 & 1.4 & 2772.02 & 7.00016 & 0.97995 & 1077.58 & 2.99974 & 0.419961 \\\\\n",
       "\t16 & 1.5 & 2771.95 & 7.00037 & 1.04995 & 1077.55 & 2.99979 & 0.449958 \\\\\n",
       "\t17 & 1.6 & 2771.88 & 7.00061 & 1.11996 & 1077.52 & 2.99985 & 0.479956 \\\\\n",
       "\t18 & 1.7 & 2771.81 & 7.00087 & 1.18996 & 1077.49 & 2.99992 & 0.509955 \\\\\n",
       "\t19 & 1.8 & 2771.74 & 7.00116 & 1.25997 & 1077.46 & 3.0 & 0.539955 \\\\\n",
       "\t20 & 1.9 & 2771.67 & 7.00148 & 1.32999 & 1077.43 & 3.00008 & 0.569955 \\\\\n",
       "\t21 & 2.0 & 2771.6 & 7.00183 & 1.4 & 1077.4 & 3.00018 & 0.599957 \\\\\n",
       "\t22 & 2.1 & 2771.53 & 7.0022 & 1.47002 & 1077.37 & 3.00029 & 0.629959 \\\\\n",
       "\t23 & 2.2 & 2771.46 & 7.0026 & 1.54005 & 1077.34 & 3.0004 & 0.659962 \\\\\n",
       "\t24 & 2.3 & 2771.39 & 7.00302 & 1.61008 & 1077.31 & 3.00053 & 0.689967 \\\\\n",
       "\t25 & 2.4 & 2771.32 & 7.00348 & 1.68011 & 1077.28 & 3.00066 & 0.719973 \\\\\n",
       "\t26 & 2.5 & 2771.25 & 7.00395 & 1.75015 & 1077.25 & 3.0008 & 0.74998 \\\\\n",
       "\t27 & 2.6 & 2771.18 & 7.00446 & 1.82019 & 1077.22 & 3.00095 & 0.779989 \\\\\n",
       "\t28 & 2.7 & 2771.1 & 7.00499 & 1.89024 & 1077.19 & 3.00112 & 0.809999 \\\\\n",
       "\t29 & 2.8 & 2771.03 & 7.00555 & 1.96029 & 1077.16 & 3.00129 & 0.840011 \\\\\n",
       "\t30 & 2.9 & 2770.96 & 7.00614 & 2.03035 & 1077.13 & 3.00147 & 0.870025 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5001×7 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m t       \u001b[0m\u001b[1m S1       \u001b[0m\u001b[1m I1       \u001b[0m\u001b[1m R1           \u001b[0m\u001b[1m S2       \u001b[0m\u001b[1m I2       \u001b[0m\u001b[1m R2     \u001b[0m ⋯\n",
       "      │\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │     0.0  2773.0     7.0         0.0        1078.0     3.0        0.0   ⋯\n",
       "    2 │     0.1  2772.93    6.99984     0.0699992  1077.97    2.99992    0.029\n",
       "    3 │     0.2  2772.86    6.9997      0.139997   1077.94    2.99985    0.059\n",
       "    4 │     0.3  2772.79    6.99959     0.209993   1077.91    2.99979    0.089\n",
       "    5 │     0.4  2772.72    6.99951     0.279989   1077.88    2.99974    0.119 ⋯\n",
       "    6 │     0.5  2772.65    6.99945     0.349984   1077.85    2.9997     0.149\n",
       "    7 │     0.6  2772.58    6.99942     0.419978   1077.82    2.99967    0.179\n",
       "    8 │     0.7  2772.51    6.99942     0.489972   1077.79    2.99964    0.209\n",
       "    9 │     0.8  2772.44    6.99945     0.559966   1077.76    2.99963    0.239 ⋯\n",
       "   10 │     0.9  2772.37    6.9995      0.629961   1077.73    2.99962    0.269\n",
       "   11 │     1.0  2772.3     6.99958     0.699956   1077.7     2.99963    0.299\n",
       "  ⋮   │    ⋮        ⋮         ⋮           ⋮           ⋮         ⋮           ⋮  ⋱\n",
       " 4992 │   499.1   746.617  28.7455   2004.64        290.33   11.1783   779.492\n",
       " 4993 │   499.2   746.34   28.7348   2004.93        290.222  11.1742   779.604 ⋯\n",
       " 4994 │   499.3   746.063  28.7242   2005.21        290.115  11.17     779.715\n",
       " 4995 │   499.4   745.787  28.7135   2005.5         290.007  11.1659   779.827\n",
       " 4996 │   499.5   745.51   28.7029   2005.79        289.899  11.1618   779.939\n",
       " 4997 │   499.6   745.234  28.6923   2006.07        289.792  11.1576   780.05  ⋯\n",
       " 4998 │   499.7   744.958  28.6816   2006.36        289.685  11.1535   780.162\n",
       " 4999 │   499.8   744.682  28.671    2006.65        289.577  11.1494   780.273\n",
       " 5000 │   499.9   744.406  28.6604   2006.93        289.47   11.1453   780.385\n",
       " 5001 │   500.0   744.13   28.6498   2007.22        289.363  11.1411   780.496 ⋯\n",
       "\u001b[36m                                                  1 column and 4980 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_reader = CSV.File(data_dir * \"SIR_\" * regions * \"_regions_\" * mobility_type * \"_\" * file * \".csv\")\n",
    "df = DataFrame(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5dcf29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>101×7 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">76 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">t</th><th style = \"text-align: left;\">S1</th><th style = \"text-align: left;\">I1</th><th style = \"text-align: left;\">R1</th><th style = \"text-align: left;\">S2</th><th style = \"text-align: left;\">I2</th><th style = \"text-align: left;\">R2</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">2773.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1078.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">2769.47</td><td style = \"text-align: right;\">7.02461</td><td style = \"text-align: right;\">3.50337</td><td style = \"text-align: right;\">1076.49</td><td style = \"text-align: right;\">3.00736</td><td style = \"text-align: right;\">1.50088</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">10.0</td><td style = \"text-align: right;\">2765.85</td><td style = \"text-align: right;\">7.11594</td><td style = \"text-align: right;\">7.03573</td><td style = \"text-align: right;\">1074.95</td><td style = \"text-align: right;\">3.03776</td><td style = \"text-align: right;\">3.0112</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">15.0</td><td style = \"text-align: right;\">2762.1</td><td style = \"text-align: right;\">7.27414</td><td style = \"text-align: right;\">10.6305</td><td style = \"text-align: right;\">1073.37</td><td style = \"text-align: right;\">3.09129</td><td style = \"text-align: right;\">4.5425</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">20.0</td><td style = \"text-align: right;\">2758.18</td><td style = \"text-align: right;\">7.49965</td><td style = \"text-align: right;\">14.3211</td><td style = \"text-align: right;\">1071.73</td><td style = \"text-align: right;\">3.16823</td><td style = \"text-align: right;\">6.1064</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">2754.07</td><td style = \"text-align: right;\">7.79326</td><td style = \"text-align: right;\">18.1415</td><td style = \"text-align: right;\">1070.02</td><td style = \"text-align: right;\">3.26898</td><td style = \"text-align: right;\">7.71469</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">30.0</td><td style = \"text-align: right;\">2749.72</td><td style = \"text-align: right;\">8.15609</td><td style = \"text-align: right;\">22.1259</td><td style = \"text-align: right;\">1068.23</td><td style = \"text-align: right;\">3.39412</td><td style = \"text-align: right;\">9.37944</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">35.0</td><td style = \"text-align: right;\">2745.1</td><td style = \"text-align: right;\">8.58952</td><td style = \"text-align: right;\">26.3093</td><td style = \"text-align: right;\">1066.34</td><td style = \"text-align: right;\">3.54436</td><td style = \"text-align: right;\">11.113</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">40.0</td><td style = \"text-align: right;\">2740.18</td><td style = \"text-align: right;\">9.09517</td><td style = \"text-align: right;\">30.7274</td><td style = \"text-align: right;\">1064.35</td><td style = \"text-align: right;\">3.72052</td><td style = \"text-align: right;\">12.9281</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">45.0</td><td style = \"text-align: right;\">2734.91</td><td style = \"text-align: right;\">9.67492</td><td style = \"text-align: right;\">35.4168</td><td style = \"text-align: right;\">1062.24</td><td style = \"text-align: right;\">3.92357</td><td style = \"text-align: right;\">14.838</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">50.0</td><td style = \"text-align: right;\">2729.25</td><td style = \"text-align: right;\">10.3308</td><td style = \"text-align: right;\">40.415</td><td style = \"text-align: right;\">1059.99</td><td style = \"text-align: right;\">4.15454</td><td style = \"text-align: right;\">16.8563</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">55.0</td><td style = \"text-align: right;\">2723.17</td><td style = \"text-align: right;\">11.065</td><td style = \"text-align: right;\">45.7607</td><td style = \"text-align: right;\">1057.59</td><td style = \"text-align: right;\">4.41456</td><td style = \"text-align: right;\">18.9974</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">60.0</td><td style = \"text-align: right;\">2716.63</td><td style = \"text-align: right;\">11.8798</td><td style = \"text-align: right;\">51.4935</td><td style = \"text-align: right;\">1055.02</td><td style = \"text-align: right;\">4.70479</td><td style = \"text-align: right;\">21.2759</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">90</td><td style = \"text-align: right;\">445.0</td><td style = \"text-align: right;\">912.452</td><td style = \"text-align: right;\">35.1312</td><td style = \"text-align: right;\">1832.42</td><td style = \"text-align: right;\">354.819</td><td style = \"text-align: right;\">13.6619</td><td style = \"text-align: right;\">712.52</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">91</td><td style = \"text-align: right;\">450.0</td><td style = \"text-align: right;\">895.691</td><td style = \"text-align: right;\">34.4832</td><td style = \"text-align: right;\">1849.83</td><td style = \"text-align: right;\">348.301</td><td style = \"text-align: right;\">13.41</td><td style = \"text-align: right;\">719.289</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">92</td><td style = \"text-align: right;\">455.0</td><td style = \"text-align: right;\">879.239</td><td style = \"text-align: right;\">33.8484</td><td style = \"text-align: right;\">1866.91</td><td style = \"text-align: right;\">341.903</td><td style = \"text-align: right;\">13.1631</td><td style = \"text-align: right;\">725.934</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">93</td><td style = \"text-align: right;\">460.0</td><td style = \"text-align: right;\">863.09</td><td style = \"text-align: right;\">33.228</td><td style = \"text-align: right;\">1883.68</td><td style = \"text-align: right;\">335.623</td><td style = \"text-align: right;\">12.9217</td><td style = \"text-align: right;\">732.455</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">94</td><td style = \"text-align: right;\">465.0</td><td style = \"text-align: right;\">847.239</td><td style = \"text-align: right;\">32.6198</td><td style = \"text-align: right;\">1900.14</td><td style = \"text-align: right;\">329.459</td><td style = \"text-align: right;\">12.6851</td><td style = \"text-align: right;\">738.856</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">95</td><td style = \"text-align: right;\">470.0</td><td style = \"text-align: right;\">831.678</td><td style = \"text-align: right;\">32.0224</td><td style = \"text-align: right;\">1916.3</td><td style = \"text-align: right;\">323.407</td><td style = \"text-align: right;\">12.4528</td><td style = \"text-align: right;\">745.14</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">96</td><td style = \"text-align: right;\">475.0</td><td style = \"text-align: right;\">816.402</td><td style = \"text-align: right;\">31.4353</td><td style = \"text-align: right;\">1932.16</td><td style = \"text-align: right;\">317.467</td><td style = \"text-align: right;\">12.2244</td><td style = \"text-align: right;\">751.308</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">97</td><td style = \"text-align: right;\">480.0</td><td style = \"text-align: right;\">801.407</td><td style = \"text-align: right;\">30.8581</td><td style = \"text-align: right;\">1947.73</td><td style = \"text-align: right;\">311.636</td><td style = \"text-align: right;\">11.9999</td><td style = \"text-align: right;\">757.364</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">98</td><td style = \"text-align: right;\">485.0</td><td style = \"text-align: right;\">786.687</td><td style = \"text-align: right;\">30.2907</td><td style = \"text-align: right;\">1963.02</td><td style = \"text-align: right;\">305.912</td><td style = \"text-align: right;\">11.7792</td><td style = \"text-align: right;\">763.309</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99</td><td style = \"text-align: right;\">490.0</td><td style = \"text-align: right;\">772.238</td><td style = \"text-align: right;\">29.7332</td><td style = \"text-align: right;\">1978.03</td><td style = \"text-align: right;\">300.293</td><td style = \"text-align: right;\">11.5624</td><td style = \"text-align: right;\">769.145</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">100</td><td style = \"text-align: right;\">495.0</td><td style = \"text-align: right;\">758.053</td><td style = \"text-align: right;\">29.186</td><td style = \"text-align: right;\">1992.76</td><td style = \"text-align: right;\">294.777</td><td style = \"text-align: right;\">11.3496</td><td style = \"text-align: right;\">774.873</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">101</td><td style = \"text-align: right;\">500.0</td><td style = \"text-align: right;\">744.13</td><td style = \"text-align: right;\">28.6498</td><td style = \"text-align: right;\">2007.22</td><td style = \"text-align: right;\">289.363</td><td style = \"text-align: right;\">11.1411</td><td style = \"text-align: right;\">780.496</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& t & S1 & I1 & R1 & S2 & I2 & R2\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0 & 2773.0 & 7.0 & 0.0 & 1078.0 & 3.0 & 0.0 \\\\\n",
       "\t2 & 5.0 & 2769.47 & 7.02461 & 3.50337 & 1076.49 & 3.00736 & 1.50088 \\\\\n",
       "\t3 & 10.0 & 2765.85 & 7.11594 & 7.03573 & 1074.95 & 3.03776 & 3.0112 \\\\\n",
       "\t4 & 15.0 & 2762.1 & 7.27414 & 10.6305 & 1073.37 & 3.09129 & 4.5425 \\\\\n",
       "\t5 & 20.0 & 2758.18 & 7.49965 & 14.3211 & 1071.73 & 3.16823 & 6.1064 \\\\\n",
       "\t6 & 25.0 & 2754.07 & 7.79326 & 18.1415 & 1070.02 & 3.26898 & 7.71469 \\\\\n",
       "\t7 & 30.0 & 2749.72 & 8.15609 & 22.1259 & 1068.23 & 3.39412 & 9.37944 \\\\\n",
       "\t8 & 35.0 & 2745.1 & 8.58952 & 26.3093 & 1066.34 & 3.54436 & 11.113 \\\\\n",
       "\t9 & 40.0 & 2740.18 & 9.09517 & 30.7274 & 1064.35 & 3.72052 & 12.9281 \\\\\n",
       "\t10 & 45.0 & 2734.91 & 9.67492 & 35.4168 & 1062.24 & 3.92357 & 14.838 \\\\\n",
       "\t11 & 50.0 & 2729.25 & 10.3308 & 40.415 & 1059.99 & 4.15454 & 16.8563 \\\\\n",
       "\t12 & 55.0 & 2723.17 & 11.065 & 45.7607 & 1057.59 & 4.41456 & 18.9974 \\\\\n",
       "\t13 & 60.0 & 2716.63 & 11.8798 & 51.4935 & 1055.02 & 4.70479 & 21.2759 \\\\\n",
       "\t14 & 65.0 & 2709.57 & 12.7773 & 57.6542 & 1052.27 & 5.02643 & 23.7074 \\\\\n",
       "\t15 & 70.0 & 2701.96 & 13.76 & 64.2848 & 1049.31 & 5.38069 & 26.3077 \\\\\n",
       "\t16 & 75.0 & 2693.74 & 14.8298 & 71.4286 & 1046.14 & 5.76873 & 29.0937 \\\\\n",
       "\t17 & 80.0 & 2684.88 & 15.9885 & 79.1295 & 1042.73 & 6.19161 & 32.0823 \\\\\n",
       "\t18 & 85.0 & 2675.33 & 17.2375 & 87.4323 & 1039.06 & 6.65025 & 35.2913 \\\\\n",
       "\t19 & 90.0 & 2665.04 & 18.578 & 96.3823 & 1035.12 & 7.14542 & 38.7386 \\\\\n",
       "\t20 & 95.0 & 2653.96 & 20.0103 & 106.025 & 1030.88 & 7.67765 & 42.4426 \\\\\n",
       "\t21 & 100.0 & 2642.06 & 21.5341 & 116.407 & 1026.33 & 8.24721 & 46.4221 \\\\\n",
       "\t22 & 105.0 & 2629.28 & 23.1482 & 127.574 & 1021.45 & 8.85394 & 50.696 \\\\\n",
       "\t23 & 110.0 & 2615.58 & 24.8501 & 139.57 & 1016.22 & 9.49723 & 55.2825 \\\\\n",
       "\t24 & 115.0 & 2600.92 & 26.6364 & 152.439 & 1010.62 & 10.176 & 60.1994 \\\\\n",
       "\t25 & 120.0 & 2585.28 & 28.5026 & 166.22 & 1004.65 & 10.8887 & 65.4642 \\\\\n",
       "\t26 & 125.0 & 2568.6 & 30.4426 & 180.953 & 998.274 & 11.6333 & 71.0929 \\\\\n",
       "\t27 & 130.0 & 2550.88 & 32.4486 & 196.672 & 991.492 & 12.4068 & 77.1013 \\\\\n",
       "\t28 & 135.0 & 2532.08 & 34.5111 & 213.41 & 984.291 & 13.2056 & 83.5034 \\\\\n",
       "\t29 & 140.0 & 2512.19 & 36.6191 & 231.191 & 976.664 & 14.0254 & 90.3108 \\\\\n",
       "\t30 & 145.0 & 2491.2 & 38.7602 & 250.036 & 968.606 & 14.8614 & 97.5324 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m101×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m t       \u001b[0m\u001b[1m S1       \u001b[0m\u001b[1m I1       \u001b[0m\u001b[1m R1         \u001b[0m\u001b[1m S2       \u001b[0m\u001b[1m I2       \u001b[0m\u001b[1m R2        \u001b[0m\n",
       "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64   \u001b[0m\n",
       "─────┼────────────────────────────────────────────────────────────────────────\n",
       "   1 │     0.0  2773.0     7.0         0.0      1078.0     3.0        0.0\n",
       "   2 │     5.0  2769.47    7.02461     3.50337  1076.49    3.00736    1.50088\n",
       "   3 │    10.0  2765.85    7.11594     7.03573  1074.95    3.03776    3.0112\n",
       "   4 │    15.0  2762.1     7.27414    10.6305   1073.37    3.09129    4.5425\n",
       "   5 │    20.0  2758.18    7.49965    14.3211   1071.73    3.16823    6.1064\n",
       "   6 │    25.0  2754.07    7.79326    18.1415   1070.02    3.26898    7.71469\n",
       "   7 │    30.0  2749.72    8.15609    22.1259   1068.23    3.39412    9.37944\n",
       "   8 │    35.0  2745.1     8.58952    26.3093   1066.34    3.54436   11.113\n",
       "   9 │    40.0  2740.18    9.09517    30.7274   1064.35    3.72052   12.9281\n",
       "  10 │    45.0  2734.91    9.67492    35.4168   1062.24    3.92357   14.838\n",
       "  11 │    50.0  2729.25   10.3308     40.415    1059.99    4.15454   16.8563\n",
       "  ⋮  │    ⋮        ⋮         ⋮          ⋮          ⋮         ⋮          ⋮\n",
       "  92 │   455.0   879.239  33.8484   1866.91      341.903  13.1631   725.934\n",
       "  93 │   460.0   863.09   33.228    1883.68      335.623  12.9217   732.455\n",
       "  94 │   465.0   847.239  32.6198   1900.14      329.459  12.6851   738.856\n",
       "  95 │   470.0   831.678  32.0224   1916.3       323.407  12.4528   745.14\n",
       "  96 │   475.0   816.402  31.4353   1932.16      317.467  12.2244   751.308\n",
       "  97 │   480.0   801.407  30.8581   1947.73      311.636  11.9999   757.364\n",
       "  98 │   485.0   786.687  30.2907   1963.02      305.912  11.7792   763.309\n",
       "  99 │   490.0   772.238  29.7332   1978.03      300.293  11.5624   769.145\n",
       " 100 │   495.0   758.053  29.186    1992.76      294.777  11.3496   774.873\n",
       " 101 │   500.0   744.13   28.6498   2007.22      289.363  11.1411   780.496\n",
       "\u001b[36m                                                               80 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = range(1,stop=5001,step=50)\n",
    "df = df[index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6f4292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101-element Vector{Float64}:\n",
       "   0.0\n",
       "   5.0\n",
       "  10.0\n",
       "  15.0\n",
       "  20.0\n",
       "  25.0\n",
       "  30.0\n",
       "  35.0\n",
       "  40.0\n",
       "  45.0\n",
       "  50.0\n",
       "  55.0\n",
       "  60.0\n",
       "   ⋮\n",
       " 445.0\n",
       " 450.0\n",
       " 455.0\n",
       " 460.0\n",
       " 465.0\n",
       " 470.0\n",
       " 475.0\n",
       " 480.0\n",
       " 485.0\n",
       " 490.0\n",
       " 495.0\n",
       " 500.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Matrix(df[:, [:S1, :I1, :R1]])'\n",
    "t = df.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3657ba91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 2773.0\n",
       "    7.0\n",
       "    0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tspan=(t[begin], t[end])\n",
    "tsteps = range(tspan[1], tspan[2], length = size(t)[1])\n",
    "\n",
    "u0 = X[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d450546e",
   "metadata": {},
   "source": [
    "### Neural ODE for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = FastChain(\n",
    "    FastDense(3, 64, tanh), FastDense(64, 64, tanh), FastDense(64, 1)\n",
    ")\n",
    "\n",
    "p = [rand(Float32, 3); initial_params(ann)]\n",
    "\n",
    "function dudt!(du, u, p, t)\n",
    "\n",
    "    z = ann(u, p[3:end])\n",
    "\n",
    "    # S, I, R = u\n",
    "    # β, γ, N = p[1:3]\n",
    "\n",
    "    N = 2000\n",
    "\n",
    "    du[1] = -p[1] * u[1] * u[2] / N - z[1] #dS\n",
    "    du[2] = p[1] * u[1] * u[2] / N - p[2] * u[2] #dI\n",
    "    du[3] = p[2] * u[2] #dR\n",
    "end\n",
    "\n",
    "prob_UODE = ODEProblem(dudt!, u0, tspan, p) ##prob_neuralode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Function to train the network\n",
    "# Define a predictor\n",
    "function predict(θ, X=X[:, 1], T=t)\n",
    "    Array(solve(prob_UODE, Vern7(), u0=X, p=θ,\n",
    "        tspan=(T[1], T[end]), saveat=T,\n",
    "        abstol=1e-6, reltol=1e-6,\n",
    "        sensealg=ForwardDiffSensitivity()\n",
    "    ))\n",
    "end\n",
    "\n",
    "\n",
    "# Define parameters for Multiple Shooting\n",
    "group_size = 5\n",
    "continuity_term = 200.0f0\n",
    "\n",
    "function loss(data, pred)\n",
    "    return sum(abs2, data - pred)\n",
    "end\n",
    "\n",
    "function shooting_loss(p)\n",
    "    return multiple_shoot(p, X, t, prob_UODE, loss, Vern7(),\n",
    "        group_size; continuity_term)\n",
    "end\n",
    "\n",
    "function loss(θ)\n",
    "    X̂ = predict(θ)\n",
    "    sum(abs2, X - X̂) / size(X, 2) + convert(eltype(θ), 1e-3) * sum(abs2, θ[3:end]) ./ length(θ[3:end])\n",
    "end\n",
    "\n",
    "# Container to track the losses\n",
    "losses = Float32[]\n",
    "\n",
    "# Callback to show the loss during training\n",
    "callback(θ, args...) = begin\n",
    "    l = loss(θ) # Equivalent L2 loss\n",
    "    push!(losses, l)\n",
    "    if length(losses) % 5 == 0\n",
    "        println(\"Current loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "    end\n",
    "    false\n",
    "end\n",
    "\n",
    "## Training -> First shooting / batching to get a rough estimate\n",
    "\n",
    "# First train with ADAM for better convergence -> move the parameters into a\n",
    "# favourable starting positing for BFGS\n",
    "res1 = DiffEqFlux.sciml_train(shooting_loss, p, ADAM(0.1f0), cb=callback, maxiters=100)\n",
    "println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "# Train with BFGS to achieve partial fit of the data\n",
    "res2 = DiffEqFlux.sciml_train(shooting_loss, res1.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters=500)\n",
    "println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "# Full L2-Loss for full prediction\n",
    "res3 = DiffEqFlux.sciml_train(loss, res2.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters=100)\n",
    "println(\"Final training loss after $(length(losses)) iterations: $(losses[end])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_preds = predict_neuralode(result_neuralode2.u)\n",
    "\n",
    "pS = plot(tsteps, [X[1,:], node_preds[1,:]], label=[\"data S\" \"prediction S\"])\n",
    "pI = plot(tsteps, [X[2,:], node_preds[2,:]], label=[\"data I\" \"prediction I\"])\n",
    "pR = plot(tsteps, [X[3,:], node_preds[3,:]], label=[\"data R\" \"prediction R\"])\n",
    "\n",
    "display(plot(pS, pI, pR, layout = (3,1), size = (800, 800)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717de709",
   "metadata": {},
   "source": [
    "## Universal Differential Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ann = FastChain(FastDense(3, 16, tanh),\n",
    "    # FastDense(50, 50, tanh),\n",
    "    FastDense(16, 1))\n",
    "\n",
    "p = [rand(Float32, 3); initial_params(ann)]\n",
    "\n",
    "function dudt_(du, u, p, t)\n",
    "    \n",
    "    S, I, R = u\n",
    "    β, γ, N  = p[1:3]\n",
    "\n",
    "    z  = ann(u, p[3:end])\n",
    "    dS = -β * S * I/N - z[1]  # susceptible\n",
    "    dI =  β * S * I/N - γ*I  # infected\n",
    "    dR =  γ * I\n",
    "\n",
    "    du[1] = dS\n",
    "    du[2] = dI\n",
    "    du[3] = dR\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the problem\n",
    "prob_UODE = ODEProblem(dudt_, u0, tspan, p) ##prob_neuralode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7fbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define parameters for Multiple Shooting\n",
    "# group_size = 5\n",
    "# continuity_term = 200.0f0\n",
    "\n",
    "# function loss1(data, pred)\n",
    "#     return sum(abs2, data - pred)\n",
    "# end\n",
    "\n",
    "# function shooting_loss(p)\n",
    "#     return multiple_shoot(p, X, t, prob_UODE, loss, Vern7(),\n",
    "#                           group_size; continuity_term)\n",
    "# end\n",
    "\n",
    "\n",
    "function predict(θ)\n",
    "    Array(solve(prob_UODE, Vern7(), u0=u0, p=θ, tspan=tspan, saveat=t))\n",
    "end\n",
    "\n",
    "function loss(θ)\n",
    "    X̂ = predict(θ)\n",
    "    sum(abs2, X - X̂) #/ size(X, 2) + convert(eltype(θ), 1e-3)*sum(abs2, θ[3:end]) ./ length(θ[3:end])\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Container to track the losses\n",
    "losses = Float32[]\n",
    "\n",
    "# Callback to show the loss during training\n",
    "callback(θ,args...) = begin\n",
    "\tl = loss(θ) # Equivalent L2 loss\n",
    "    push!(losses, l)\n",
    "    if length(losses)%5==0\n",
    "        println(\"Current loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "    end\n",
    "    false\n",
    "end\n",
    "\n",
    "callback(p)\n",
    "\n",
    "## Training -> First shooting / batching to get a rough estimate\n",
    "\n",
    "# First train with ADAM for better convergence -> move the parameters into a\n",
    "# favourable starting positing for BFGS\n",
    "\n",
    "\n",
    "    \n",
    "    # Train with BFGS to achieve partial fit of the data\n",
    "# res2 = DiffEqFlux.sciml_train(shooting_loss, res1.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters = 500)\n",
    "# println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # # Full L2-Loss for full prediction\n",
    "# res3 = DiffEqFlux.sciml_train(loss, res2.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters = 10000)\n",
    "# println(\"Final training loss after $(length(losses)) iterations: $(losses[end])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ca0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_fit = DiffEqFlux.sciml_train(loss, p, BFGS(initial_stepnorm=0.1f0), maxiters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Optimization.jl to solve the problem\n",
    "adtype = Optimization.AutoZygote()\n",
    "optf    = Optimization.OptimizationFunction((x,p) -> loss(x), adtype)\n",
    "optprob = Optimization.OptimizationProblem(optf, p)\n",
    "\n",
    "result_neuralode = Optimization.solve(optprob, ADAM(0.05), tspan=tspan, saveat=t, maxiters = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e897372",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neuralode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_uode = Array(result_neuralode)\n",
    "\n",
    "pS = plot(tsteps, [X[1,:], preds_uode[1,:]], label=[\"data S\" \"prediction S\"])\n",
    "pI = plot(tsteps, [X[2,:], preds_uode[2,:]], label=[\"data I\" \"prediction I\"])\n",
    "pR = plot(tsteps, [X[3,:], preds_uode[3,:]], label=[\"data R\" \"prediction R\"])\n",
    "\n",
    "display(plot(pS, pI, pR, layout = (3,1), size = (800, 800)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216d1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ec52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbacc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f314749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4fa271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb0f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bebf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to plot the loss using Optimization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(result_neuralode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c37674",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neuralode.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2771c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reduce(hcat,result_neuralode.u)\n",
    "t = result_neuralode.t\n",
    "\n",
    "tspan = (t[begin], t[end])\n",
    "\n",
    "steps = range(1,87)\n",
    "\n",
    "\n",
    "# println(tsteps)\n",
    "\n",
    "# pred = predict(p_trained, X[:,1], tsample)\n",
    "\n",
    "pS = scatter(pred[1,:], label = \"data S\")\n",
    "\n",
    "# # # # scatter!(pS, tsteps, pred[1,:], label = \"prediction S\")\n",
    "\n",
    "pI = scatter(pred[2,:], label = \"data I\")\n",
    "scatter!(pI, tsteps, pred[2,:], label = \"prediction I\")\n",
    "        \n",
    "# # # # pR = scatter(tsteps, X[3,:], label = \"data R\")b\n",
    "# # # # scatter!(pR, tsteps, pred[3,:], label = \"prediction R\")\n",
    "   \n",
    "display(plot(pS, pI, layout = (3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1db734",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis of the trained network\n",
    "# Interpolate the solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54429121",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neuralode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153eef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Optimization.jl to solve the problem\n",
    "adtype = Optimization.AutoZygote()\n",
    "\n",
    "optf = Optimization.OptimizationFunction(loss, adtype)\n",
    "optprob = Optimization.OptimizationProblem(optf, p)\n",
    "\n",
    "result_neuralode = Optimization.solve(prob_UODE,\n",
    "                                       Tsit5(),\n",
    "#                                        callback = callback,\n",
    "                                       maxiters = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822969f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function predict(θ)\n",
    "    Array(concrete_solve(prob_UODE, Vern7(), u0, θ, saveat = t))\n",
    "end\n",
    "\n",
    "# No regularisation right now\n",
    "function loss(θ)\n",
    "    pred = predict(θ)\n",
    "    sum(abs2, X .- pred), pred # + 1e-5*sum(sum.(abs, params(ann)))\n",
    "end\n",
    "\n",
    "loss(p)\n",
    "\n",
    "const losses = []\n",
    "callback(θ,l,pred) = begin\n",
    "    push!(losses, l)\n",
    "#     if length(losses)%50==0\n",
    "#         println(losses[end])\n",
    "#     end\n",
    "#     false\n",
    "end\n",
    "\n",
    "res1_uode = DiffEqFlux.sciml_train(loss, p, ADAM(0.01), cb=callback, maxiters = 5)\n",
    "# res2_uode = DiffEqFlux.sciml_train(loss, res1_uode.minimizer, BFGS(initial_stepnorm=0.01), cb=callback, maxiters = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da187ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function predict(θ, X=X[:,1], T=t)\n",
    "#     Array(solve(prob_UODE, Vern7(), u0=X, p=θ, tspan=tspan, saveat=T))\n",
    "#     end\n",
    "    \n",
    "    \n",
    "    \n",
    "# function loss(data, pred)\n",
    "# \treturn sum(abs2, data - pred)\n",
    "# end\n",
    "\n",
    "    \n",
    "    \n",
    "function loss(θ)\n",
    "    X̂ = predict(θ)\n",
    "    sum(abs2, Xₙ - X̂) / size(Xₙ, 2) + convert(eltype(θ), 1e-3)*sum(abs2, θ[3:end]) ./ length(θ[3:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Optimization.jl to solve the problem\n",
    "adtype = Optimization.AutoZygote()\n",
    "\n",
    "optf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\n",
    "optprob = Optimization.OptimizationProblem(optf, pinit)\n",
    "\n",
    "result_neuralode = Optimization.solve(prob_UODE,\n",
    "                                       Adam(0.05),\n",
    "#                                        callback = callback,\n",
    "                                       maxiters = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neuralode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container to track the losses\n",
    "losses = Float32[]\n",
    "\n",
    "# Callback to show the loss during training\n",
    "callback(θ,args...) = begin\n",
    "\tl = loss(θ) # Equivalent L2 loss\n",
    "    print(l)\n",
    "    push!(losses, l)\n",
    "    if length(losses)%5==0\n",
    "        println(\"Current loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "    end\n",
    "    false\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e42115",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training -> First shooting / batching to get a rough estimate\n",
    "\n",
    "# First train with ADAM for better convergence -> move the parameters into a\n",
    "# favourable starting positing for BFGS\n",
    "res1 = DiffEqFlux.sciml_train(shooting_loss, p, ADAM(0.1f0), cb=callback, maxiters = 100)\n",
    "println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "# Train with BFGS to achieve partial fit of the data\n",
    "res2 = DiffEqFlux.sciml_train(shooting_loss, res1.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters = 500)\n",
    "println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "# Full L2-Loss for full prediction\n",
    "res3 = DiffEqFlux.sciml_train(loss, res2.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters = 10000)\n",
    "println(\"Final training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = DiffEqFlux.sciml_train(loss, p, ADAM(0.1f0), cb=callback, maxiters = 100)\n",
    "println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_trained = res1.minimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67dbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "using DiffEqFlux, DifferentialEquations, Optimization, OptimizationOptimJL, Random, Plots, CSV, Lux, DataFrames\n",
    "using DataDrivenDiffEq, ModelingToolkit, LinearAlgebra, DiffEqSensitivity, Zygote, Optim, CSV, Lux, Pkg, Flux\n",
    "gr()\n",
    "Pkg.status()\n",
    "\n",
    "\n",
    "data_dir = \"/Users/adrocampos/covid19/synth_data/\"\n",
    "regions = [\"2\", \"3\", \"5\", \"10\", \"15\", \"20\", \"30\"][1]\n",
    "mobility_type = [\"inv_dist\", \"border\", \"neighbor\"][2]\n",
    "initially_recovered = false\n",
    "\n",
    "# positions = CSV.File(data_dir * \"positions_\" * regions * \"_regions.csv\")\n",
    "# positions = DataFrame(positions)\n",
    "\n",
    "file = \"1\"\n",
    "\n",
    "csv_reader = CSV.File(data_dir * \"SIR_\" * regions * \"_regions_\" * mobility_type * \"_\" * file * \".csv\")\n",
    "df = DataFrame(csv_reader)\n",
    "\n",
    "\n",
    "index = range(1, stop=5001, step=50)\n",
    "df = df[index, :]\n",
    "\n",
    "X = Matrix(df[:, [:S1, :I1, :R1]])'\n",
    "t = df.t\n",
    "\n",
    "tspan = (t[begin], t[end])\n",
    "tsteps = range(tspan[1], tspan[2], length=size(t)[1])\n",
    "\n",
    "u0 = X[:, 1]\n",
    "\n",
    "\n",
    "ann = FastChain(FastDense(3, 16, tanh),\n",
    "    # FastDense(50, 50, tanh),\n",
    "    FastDense(16, 3))\n",
    "\n",
    "\n",
    "\n",
    "## Firs the parameters for Beta, gama und N, then the weigths. \n",
    "\n",
    "# Get the initial parameters, first two is linear birth / decay of prey and predator\n",
    "\n",
    "# Get the initial parameters, first two is linear birth / decay of prey and predator\n",
    "\n",
    "# ps, st = Lux.setup(rng, ann)\n",
    "\n",
    "## Firs the parameters for Beta, gama und N, then the weigths. \n",
    "\n",
    "# Get the initial parameters, first two is linear birth / decay of prey and predator\n",
    "p = [rand(Float32, 3); initial_params(ann)]\n",
    "\n",
    "function dudt_(du, u, p, t)\n",
    "\n",
    "    S, I, R = u\n",
    "    β, γ, N = p[1:3]\n",
    "\n",
    "    # z = ann(u, p[3:end])\n",
    "    # dS = -β * S * I / N - z[1]  # susceptible\n",
    "    # dI = β * S * I / N - γ * I - z[1] # infected\n",
    "    # dR = γ * I\n",
    "\n",
    "    # du[1] = dS\n",
    "    # du[2] = dI\n",
    "    # du[3] = dR\n",
    "\n",
    "    du[1], du[2], du[3] = ann(u, p[3:end])\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the problem\n",
    "prob_UODE = ODEProblem(dudt_, u0, tspan, p) ##prob_neuralode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function predict(θ)\n",
    "    Array(solve(prob_UODE, Vern7(), u0=u0, p=θ, tspan=tspan, saveat=t))\n",
    "end\n",
    "\n",
    "function loss(θ)\n",
    "    X̂ = predict(θ)\n",
    "    sum(abs2, X - X̂) / size(X, 2) + convert(eltype(θ), 1e-3) * sum(abs2, θ[3:end]) ./ length(θ[3:end])\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Container to track the losses\n",
    "losses = Float32[]\n",
    "\n",
    "# Callback to show the loss during training\n",
    "callback(θ, args...) = begin\n",
    "    l = loss(θ) # Equivalent L2 loss\n",
    "    push!(losses, l)\n",
    "    if length(losses) % 5 == 0\n",
    "        println(\"Current loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "    end\n",
    "    false\n",
    "end\n",
    "\n",
    "callback(p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Training -> First shooting / batching to get a rough estimate\n",
    "\n",
    "# First train with ADAM for better convergence -> move the parameters into a\n",
    "# favourable starting positing for BFGS\n",
    "\n",
    "\n",
    "# res1 = DiffEqFlux.sciml_train(shooting_loss, p, Adam(0.1f0), cb=callback, maxiters=1)\n",
    "# println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "# Train with BFGS to achieve partial fit of the data\n",
    "# res2 = DiffEqFlux.sciml_train(shooting_loss, res1.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters = 500)\n",
    "# println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "# # Full L2-Loss for full prediction\n",
    "# res3 = DiffEqFlux.sciml_train(loss, res2.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters = 10000)\n",
    "# println(\"Final training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "\n",
    "# use Optimization.jl to solve the problem\n",
    "adtype = Optimization.AutoZygote()\n",
    "\n",
    "optf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\n",
    "optprob = Optimization.OptimizationProblem(optf, p)\n",
    "\n",
    "result_neuralode = Optimization.solve(optprob, ADAM(0.05), tspan=tspan, saveat=t, maxiters=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe3b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
