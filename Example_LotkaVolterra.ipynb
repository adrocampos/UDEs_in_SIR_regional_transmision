{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9a2ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FileIO ─ v1.16.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JLD2 ─── v0.4.28\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/covid19/discovering_missing_terms/Project.toml`\n",
      " \u001b[90m [033835bb] \u001b[39m\u001b[92m+ JLD2 v0.4.28\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/covid19/discovering_missing_terms/Manifest.toml`\n",
      " \u001b[90m [5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.16.0\u001b[39m\n",
      " \u001b[90m [033835bb] \u001b[39m\u001b[92m+ JLD2 v0.4.28\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFileIO\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mJLD2\n",
      "  2 dependencies successfully precompiled in 12 seconds (382 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"JLD2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0828bd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/covid19/discovering_missing_terms/Project.toml`\n",
      " \u001b[90m [5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.16.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/covid19/discovering_missing_terms/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"FileIO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaa9e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/covid19/discovering_missing_terms`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Environment and packages\n",
    "cd(@__DIR__)\n",
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n",
    "\n",
    "using OrdinaryDiffEq\n",
    "using ModelingToolkit\n",
    "using DataDrivenDiffEq\n",
    "using LinearAlgebra, Optim\n",
    "using DiffEqFlux, Flux\n",
    "using Plots\n",
    "gr()\n",
    "using JLD2, FileIO\n",
    "using Statistics\n",
    "using DelimitedFiles\n",
    "# Set a random seed for reproduceable behaviour\n",
    "using Random\n",
    "Random.seed!(5443)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f34070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mSTLSQ   2%|▊                                             |  ETA: 0:01:17\u001b[39m\r\n",
      "\u001b[34m  Threshold:          1.2589254e-7\u001b[39m\r\n",
      "\u001b[34m  Best Objective:     0.15061031\u001b[39m\r\n",
      "\u001b[34m  Best Sparsity:      23.0\u001b[39m\r\n",
      "\u001b[34m  Current Objective:  0.15061031\u001b[39m\r\n",
      "\u001b[34m  Current Sparsity:   23.0\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Solution with 2 equations and 6 parameters.\n",
      "Returncode: solved\n",
      "L₂ Norm error : Float32[0.16268602, 0.20055747]\n",
      "AIC : Float32[-26.134598, -21.739742]\n",
      "R² : Float32[0.76230365, 0.7225896]\n",
      "\n",
      "\u001b[0m\u001b[1mModel ##Basis#337 with 2 equations\u001b[22m\n",
      "States : u[1] u[2]\n",
      "Parameters : 6\n",
      "Independent variable: t\n",
      "Equations\n",
      "Differential(t)(u[1]) = p₁*(u[1]^2) + p₂*u[1]*u[2]\n",
      "Differential(t)(u[2]) = p₅*(u[2]^3) + p₃*u[2] + p₆*sin(u[2]) + p₄*(u[2]^2)*u[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: FastChain is being deprecated in favor of Lux.jl. Lux.jl uses functions with explicit parameters f(u,p) like FastChain, but is fully featured and documented machine learning library. See the Lux.jl documentation for more details.\n",
      "└ @ DiffEqFlux /Users/adrocampos/.julia/packages/DiffEqFlux/Em1Aj/src/fast_layers.jl:9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(::FastChain{Tuple{FastDense{typeof(rbf), DiffEqFlux.var\"#initial_params#107\"{Vector{Float32}}, Nothing}, FastDense{typeof(rbf), DiffEqFlux.var\"#initial_params#107\"{Vector{Float32}}, Nothing}, FastDense{typeof(tanh_fast), DiffEqFlux.var\"#initial_params#107\"{Vector{Float32}}, Nothing}, FastDense{typeof(identity), DiffEqFlux.var\"#initial_params#107\"{Vector{Float32}}, Nothing}}}) (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### NOTE\n",
    "# Since the recent release of DataDrivenDiffEq v0.6.0 where a complete overhaul of the optimizers took\n",
    "# place, SR3 has been used. Right now, STLSQ performs better and has been changed.\n",
    "# Additionally, the behaviour of the optimization has changed slightly. This has been adjusted\n",
    "# by decreasing the tolerance of the gradient.\n",
    "\n",
    "\n",
    "svname = \"HudsonBay\"\n",
    "## Data Preprocessing\n",
    "# The data has been taken from https://jmahaffy.sdsu.edu/courses/f00/math122/labs/labj/q3v1.htm\n",
    "# Originally published in E. P. Odum (1953), Fundamentals of Ecology, Philadelphia, W. B. Saunders\n",
    "hudson_bay_data = readdlm(\"hudson_bay_data.dat\", '\\t', Float32, '\\n')\n",
    "# Measurements of prey and predator\n",
    "Xₙ = Matrix(transpose(hudson_bay_data[:, 2:3]))\n",
    "t = hudson_bay_data[:, 1] .- hudson_bay_data[1, 1]\n",
    "# Normalize the data; since the data domain is strictly positive\n",
    "# we just need to divide by the maximum\n",
    "xscale = maximum(Xₙ, dims =2)\n",
    "Xₙ .= 1f0 ./ xscale .* Xₙ\n",
    "# Time from 0 -> n\n",
    "tspan = (t[1], t[end])\n",
    "\n",
    "# Plot the data\n",
    "scatter(t, transpose(Xₙ), xlabel = \"t\", ylabel = \"x(t), y(t)\")\n",
    "plot!(t, transpose(Xₙ), xlabel = \"t\", ylabel = \"x(t), y(t)\")\n",
    "\n",
    "## Direct Identification via SINDy + Collocation\n",
    "\n",
    "# Create the problem using a gaussian kernel for collocation\n",
    "full_problem = ContinuousDataDrivenProblem(Xₙ, t, DataDrivenDiffEq.GaussianKernel())\n",
    "# Look at the collocation\n",
    "plot(full_problem.t, full_problem.X')\n",
    "plot(full_problem.t, full_problem.DX')\n",
    "\n",
    "# Create a Basis\n",
    "@variables u[1:2]\n",
    "\n",
    "# Generate the basis functions, multivariate polynomials up to deg 5\n",
    "# and sine\n",
    "b = [polynomial_basis(u, 5); sin.(u)]\n",
    "basis = Basis(b, u)\n",
    "\n",
    "# Create the thresholds which should be used in the search process\n",
    "λ = Float32.(exp10.(-7:0.1:5))\n",
    "# Create an optimizer for the SINDy problem\n",
    "opt = STLSQ(λ)\n",
    "\n",
    "# Best result so far\n",
    "full_res = solve(full_problem, basis, opt, maxiter = 10000, progress = true, denoise = true, normalize = true)\n",
    "\n",
    "println(full_res)\n",
    "println(result(full_res))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb383557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: FastChain is being deprecated in favor of Lux.jl. Lux.jl uses functions with explicit parameters f(u,p) like FastChain, but is fully featured and documented machine learning library. See the Lux.jl documentation for more details.\n",
      "└ @ DiffEqFlux /Users/adrocampos/.julia/packages/DiffEqFlux/Em1Aj/src/fast_layers.jl:9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89-element Vector{Float32}:\n",
       "  0.17893368\n",
       "  0.69225025\n",
       " -0.12446875\n",
       "  0.71767193\n",
       " -0.50356054\n",
       "  0.72778094\n",
       " -0.9166934\n",
       " -0.87155926\n",
       " -0.15054137\n",
       " -0.1562579\n",
       "  0.048088938\n",
       " -0.7277233\n",
       "  0.0\n",
       "  ⋮\n",
       "  0.4047644\n",
       "  0.5246952\n",
       "  0.44054243\n",
       "  0.11847917\n",
       " -0.1049189\n",
       " -0.63704336\n",
       " -0.07101093\n",
       "  0.45443735\n",
       "  0.059040703\n",
       " -0.32853702\n",
       "  0.0\n",
       "  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define the network\n",
    "# Gaussian RBF as activation\n",
    "rbf(x) = exp.(-(x.^2))\n",
    "\n",
    "# Define the network 2->5->5->5->2\n",
    "U = FastChain(\n",
    "    FastDense(2,5,rbf), FastDense(5,5, rbf), FastDense(5,5, tanh), FastDense(5,2)\n",
    ")\n",
    "\n",
    "# Get the initial parameters, first two is linear birth / decay of prey and predator\n",
    "p = [rand(Float32,2); initial_params(U)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c88f1f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×21 Matrix{Float32}:\n",
       " 0.387597   0.609819  0.906977  1.0       …  0.18863  0.209302  0.319121\n",
       " 0.0673401  0.102694  0.164983  0.592593     0.1633   0.170034  0.144781"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xₙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bc4f854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float32}:\n",
       " 0.38759688\n",
       " 0.06734007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xₙ[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60700db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the hybrid model\n",
    "function ude_dynamics!(du,u, p, t)\n",
    "    û = U(u, p[3:end]) # Network prediction\n",
    "    # We assume a linear birth rate for the prey\n",
    "    du[1] = p[1]*u[1] + û[1]\n",
    "    # We assume a linear decay rate for the predator\n",
    "    du[2] = -p[2]*u[2] + û[2]\n",
    "end\n",
    "\n",
    "# Define the problem\n",
    "prob_nn = ODEProblem(ude_dynamics!,Xₙ[:, 1], tspan, p)\n",
    "\n",
    "## Function to train the network\n",
    "# Define a predictor\n",
    "function predict(θ, X = Xₙ[:,1], T = t)\n",
    "    Array(solve(prob_nn, Vern7(), u0 = X, p=θ,\n",
    "                tspan = (T[1], T[end]), saveat = T,\n",
    "                abstol=1e-6, reltol=1e-6,\n",
    "                sensealg = ForwardDiffSensitivity()\n",
    "                ))\n",
    "end\n",
    "\n",
    "\n",
    "# Define parameters for Multiple Shooting\n",
    "group_size = 5\n",
    "continuity_term = 200.0f0\n",
    "\n",
    "function loss(data, pred)\n",
    "\treturn sum(abs2, data - pred)\n",
    "end\n",
    "\n",
    "function shooting_loss(p)\n",
    "    return multiple_shoot(p, Xₙ, t, prob_nn, loss, Vern7(),\n",
    "                          group_size; continuity_term)\n",
    "end\n",
    "\n",
    "function loss(θ)\n",
    "    X̂ = predict(θ)\n",
    "    sum(abs2, Xₙ - X̂) / size(Xₙ, 2) + convert(eltype(θ), 1e-3)*sum(abs2, θ[3:end]) ./ length(θ[3:end])\n",
    "end\n",
    "\n",
    "# Container to track the losses\n",
    "losses = Float32[]\n",
    "\n",
    "# Callback to show the loss during training\n",
    "callback(θ,args...) = begin\n",
    "\tl = loss(θ) # Equivalent L2 loss\n",
    "    push!(losses, l)\n",
    "    if length(losses)%5==0\n",
    "        println(\"Current loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "    end\n",
    "    false\n",
    "end\n",
    "\n",
    "## Training -> First shooting / batching to get a rough estimate\n",
    "\n",
    "# First train with ADAM for better convergence -> move the parameters into a\n",
    "# favourable starting positing for BFGS\n",
    "res1 = DiffEqFlux.sciml_train(shooting_loss, p, ADAM(0.1f0), cb=callback, maxiters = 100)\n",
    "println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "\n",
    "# Train with BFGS to achieve partial fit of the data\n",
    "res2 = DiffEqFlux.sciml_train(shooting_loss, res1.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters = 500)\n",
    "println(\"Training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "\n",
    "# Full L2-Loss for full prediction\n",
    "res3 = DiffEqFlux.sciml_train(loss, res2.minimizer, BFGS(initial_stepnorm=0.01f0), cb=callback, maxiters = 10000)\n",
    "println(\"Final training loss after $(length(losses)) iterations: $(losses[end])\")\n",
    "\n",
    "\n",
    "pl_losses = plot(1:101, losses[1:101], yaxis = :log10, xaxis = :log10, xlabel = \"Iterations\", ylabel = \"Loss\", label = \"ADAM (Shooting)\", color = :blue)\n",
    "plot!(102:302, losses[102:302], yaxis = :log10, xaxis = :log10, xlabel = \"Iterations\", ylabel = \"Loss\", label = \"BFGS (Shooting)\", color = :red)\n",
    "plot!(302:length(losses), losses[302:end], color = :black, label = \"BFGS (L2)\")\n",
    "savefig(pl_losses, joinpath(pwd(), \"plots\", \"$(svname)_losses.pdf\"))\n",
    "\n",
    "# Rename the best candidate\n",
    "p_trained = res3.minimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4538fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Analysis of the trained network\n",
    "# Interpolate the solution\n",
    "tsample = t[1]:0.5:t[end]\n",
    "X̂ = predict(p_trained, Xₙ[:,1], tsample)\n",
    "# Trained on noisy data vs real solution\n",
    "pl_trajectory = scatter(t, transpose(Xₙ), color = :black, label = [\"Measurements\" nothing], xlabel = \"t\", ylabel = \"x(t), y(t)\")\n",
    "plot!(tsample, transpose(X̂), color = :red, label = [\"UDE Approximation\" nothing])\n",
    "savefig(pl_trajectory, joinpath(pwd(), \"plots\", \"$(svname)_trajectory_reconstruction.pdf\"))\n",
    "\n",
    "# Neural network guess\n",
    "Ŷ = U(X̂,p_trained[3:end])\n",
    "\n",
    "pl_reconstruction = scatter(tsample, transpose(Ŷ), xlabel = \"t\", ylabel =\"U(x,y)\", color = :red, label = [\"UDE Approximation\" nothing])\n",
    "plot!(tsample, transpose(Ŷ), color = :red, lw = 2, style = :dash, label = [nothing nothing])\n",
    "savefig(pl_reconstruction, joinpath(pwd(), \"plots\", \"$(svname)_missingterm_reconstruction.pdf\"))\n",
    "pl_missing = plot(pl_trajectory, pl_reconstruction, layout = (2,1))\n",
    "savefig(pl_missing, joinpath(pwd(), \"plots\", \"$(svname)_reconstruction.pdf\"))\n",
    "## Symbolic regression via sparse regression (SINDy based)\n",
    "# We reuse the basis and optimizer defined at the beginning\n",
    "\n",
    "nn_problem = ContinuousDataDrivenProblem(X̂, tsample, DX = Ŷ)\n",
    "nn_res = solve(nn_problem, basis, opt, maxiter = 10000, progress = true, normalize = false, denoise = true)\n",
    "println(nn_res)\n",
    "println(result(nn_res))\n",
    "\n",
    "# Define the recovered, hyrid model with the rescaled dynamics\n",
    "function recovered_dynamics!(du,u, p, t)\n",
    "    û = nn_res(u, p[3:end]) # Network prediction\n",
    "    du[1] = p[1]*u[1] + û[1]\n",
    "    du[2] = -p[2]*u[2] + û[2]\n",
    "end\n",
    "\n",
    "\n",
    "p_model = [p_trained[1:2];parameters(nn_res)]\n",
    "\n",
    "estimation_prob = ODEProblem(recovered_dynamics!, Xₙ[:, 1], tspan, p_model)\n",
    "# Convert for reuse\n",
    "sys = modelingtoolkitize(estimation_prob);\n",
    "dudt = ODEFunction(sys);\n",
    "estimation_prob = ODEProblem(dudt,Xₙ[:, 1], tspan, p_model)\n",
    "estimate = solve(estimation_prob, Tsit5(), saveat = t)\n",
    "\n",
    "##  Fit the found model\n",
    "function loss_fit(θ)\n",
    "    X̂ = Array(solve(estimation_prob, Tsit5(), p = θ, saveat = t))\n",
    "    sum(abs2, X̂ .- Xₙ)\n",
    "end\n",
    "\n",
    "# Post-fit the model\n",
    "res_fit = DiffEqFlux.sciml_train(loss_fit, p_model, BFGS(initial_stepnorm = 0.1f0), maxiters = 1000)\n",
    "p_fitted = res_fit.minimizer\n",
    "\n",
    "# Estimate\n",
    "estimate_rough = solve(estimation_prob, Tsit5(), saveat = 0.1*mean(diff(t)), p = p_model)\n",
    "estimate = solve(estimation_prob, Tsit5(), saveat = 0.1*mean(diff(t)), p = p_fitted)\n",
    "\n",
    "# Plot\n",
    "pl_fitted = plot(t, transpose(Xₙ), style = :dash, lw = 2,color = :black, label = [\"Measurements\" nothing], xlabel = \"t\", ylabel = \"x(t), y(t)\")\n",
    "plot!(estimate_rough, color = :red, label = [\"Recovered\" nothing])\n",
    "plot!(estimate, color = :blue, label = [\"Recovered + Fitted\" nothing])\n",
    "savefig(pl_fitted,joinpath(pwd(),\"plots\",\"$(svname)recovery_fitting.pdf\"))\n",
    "\n",
    "## Simulation\n",
    "\n",
    "# Look at long term prediction\n",
    "t_long = (0.0f0, 50.0f0)\n",
    "estimate_long = solve(estimation_prob, Tsit5(), saveat = 0.25f0, tspan = t_long,p = p_fitted)\n",
    "plot(estimate_long.t, transpose(xscale .* estimate_long[:,:]), xlabel = \"t\", ylabel = \"x(t),y(t)\")\n",
    "\n",
    "\n",
    "## Save the results\n",
    "save(joinpath(pwd(),\"results\",\"Hudson_Bay_recovery.jld2\"),\n",
    "    \"X\", Xₙ, \"t\" , t, \"neural_network\" , U, \"initial_parameters\", p, \"trained_parameters\" , p_trained, # Training\n",
    "    \"losses\", losses, \"result\", nn_res, \"recovered_parameters\", parameters(nn_res), # Recovery\n",
    "    \"model\", recovered_dynamics!, \"model_parameter\", p_model, \"fitted_parameter\", p_fitted,\n",
    "    \"long_estimate\", estimate_long) # Estimation\n",
    "\n",
    "## Post Processing and Plots\n",
    "\n",
    "c1 = 3 # RGBA(174/255,192/255,201/255,1) # Maroon\n",
    "c2 = :orange # RGBA(132/255,159/255,173/255,1) # Red\n",
    "c3 = :blue # RGBA(255/255,90/255,0,1) # Orange\n",
    "c4 = :purple # RGBA(153/255,50/255,204/255,1) # Purple\n",
    "\n",
    "p3 = scatter(t, transpose(Xₙ), color = [c1 c2], label = [\"x data\" \"y data\"],\n",
    "             title = \"Recovered Model from Hudson Bay Data\",\n",
    "             titlefont = \"Helvetica\", legendfont = \"Helvetica\",\n",
    "             markersize = 5)\n",
    "\n",
    "plot!(p3,estimate_long, color = [c3 c4], lw=1, label = [\"Estimated x(t)\" \"Estimated y(t)\"])\n",
    "plot!(p3,[19.99,20.01],[0.0,maximum(Xₙ)*1.25],lw=1,color=:black, label = nothing)\n",
    "annotate!([(10.0,maximum(Xₙ)*1.25,text(\"Training \\nData\",12 , :center, :top, :black, \"Helvetica\"))])\n",
    "savefig(p3,joinpath(pwd(),\"plots\",\"$(svname)full_plot.pdf\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
